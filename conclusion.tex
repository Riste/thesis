\chapter{Conclusions and Discussion}\label{chap:conclusion}
\begin{quotation}
\noindent 
In this chapter we revisit the research questions outlined in Chap. \ref{chap:intro} and state the conclusions that follow from the research work presented in this thesis. We conclude with a final discussion and indicate possible research directions to extend or compliment the results described in the thesis.  
\end{quotation}

As audio-visual archives become accessible to the wider internet audience, successful retrieval of archive items is an increasingly challenging task. One of the most important reason for this is the lack of adequate annotations. Users cannot find what they are looking for because annotations are either not
present or too expert-centric. Video tagging games are an attempt to alleviate this problem. Engaging the internet community to tag the videos addresses the issue of scarcity of annotations and yields tags that are community-centric. The focus of this thesis is on the role of game tags in audio-visual archives and their added value for video retrieval. In the typical audio-visual archive ecosystem the game tags will coexist with professionally curated annotations. To understand what do game tags bring to the table as opposed to the catalogers' annotations we studied the differences between them along two dimensions. The first dimension is the \textit{terminology}: we performed a quantitative study to estimate the \textit{terminological gap} between taggers and the catalogers. The second dimension is the \textit{descriptive scope} i.e. which aspects of the video content are described and at what level of abstraction and granularity. We carried out a qualitative study in which we analysed the descriptive scope of the game tags. Making the videos more accessible to the wider internet audience is one of the main objectives of the game tags. To evaluate the efficiency of the game tags for video retrieval we designed Cranfield-style experiments for two prominent scenarios that arise in practice: \textit{visual} and \textit{topical} search. Moreover we performed a qualitative analysis of samples of search results to establish the reasons that usually lead to true and false positives in both scenarios. The fast pace of \textit{Waisda?} usually results in players contributing mainly non-topical tags. To combat this effect in the visual search scenario, we characterized the quality of user tags as topical annotations and identified several tag features (filters) that serve as indicators whether game tags are useful for retrieval. The success of each of the filters was evaluated in Cranfield-style experiment.

The main contributions of the thesis are:
\begin{itemize}
\item A method to analyze quantitatively the overlap between user and professional terminology exploited in video annotation.
\item Qualitative analysis of the aspects of the video content which are described by the game tags i.e. \textit{what do game tags describe in a video and how}.
%\item A method of qualitative analysis of samples of user tags to establish the facets---\textit{who}, \textit{what}, \textit{where}, and \textit{when}--- of videos typically described by users and the level of specificity---\textit{abstract}, \textit{generic}, and \textit{specific}---of tags.
\item A method to design a dataset ---including fragments, queries, and relevance judgements --- for evaluating the added value of user tags for \textit{visual} and \textit{topical} video search.
\item Two evaluation datasets ---one for visual and one for topical search --- which contain fragments, user tags from \textit{Waisda?} collection, queries, and relevance judgements.
\item Quantitative evaluation of the added value of the game tags in terms of \textit{visual} and \textit{topical} video search.

\item A method for qualitative analysis/classification of the search results in the context of visual search. The aim of the analysis was to discover the types of tags that are generally responsible for false positives.

\item Qualitative analysis of the search results in the context of topical search. The aim of the analysis was to discover tagging practices that generally produce relevant topical tags.

\item Evaluation of tag-related measures for accessing the quality of the game tags as topical descriptors in the context of topical video search.

\item Development of extension module for \textit{Waisda?} which enables integration of the game in AV collection workflows. The module is part of the latest release of \textit{Waisda?} which is available online\footnote{The Waisda? source code and documentation is available from Github \url{http://github.com/beeldengeluid/waisda}}.
\end{itemize}

In this chapter we consider again the research questions stated in Chapter \ref{chap:intro} outlining the methods and results. The last section features discussion and directions for future research.

\section{Research Questions Revisited}
\subsection{What is the relationship between the game tags and professional annotations in terms of vocabulary and what they describe?}
Successful integration of the game tags into the AV collections' workflows requires a better understanding of the characteristics of the tags compared to the pre-existing professional annotations. To this end, in Chapter \ref{chap:kcap}, we studied game tags and compared them to professional annotations along two dimensions: (i) the vocabulary used i.e. the terminological gap and (ii) the aspects of the video content that is described.

Our first goal was to determine the fraction of the game tags that are meaningful words. For this purpose we matched all game tags to the general lexicon of the Dutch language Cornetto. We learned that the overlap is rather low, only one in every four unique game tags were found in Cornetto. Using the part-of-speech information provided in Cornetto we determined that the majority of the tags found in Cornetto are nouns and verbs. This means that people generally focus on objects and actions when tagging the videos. Small fraction of the game tags found in Cornetto, around $15\%$, are adjectives. Generally these are subjective descriptive words, for example the most common adjective among the tags is \textit{lekker} (\textit{nice} in Dutch). The majority of all unique game tags, around $77\%$, are not found in Cornetto. To understand if these tags are just gibberish or actually have meaning we used the Google search engine as semantic filter: we deemed a tag as meaningful only if the number of pages returned by Google is positive. Around $84\%$ of the tags not found in Cornetto were deemed meaningful by Google. A manual inspection of a random sample revealed that these tags are morphological variation or proper words, minor typos, slang, and collocations. The overall conclusion is that the majority of the game tags are meaningful words in themselves. This analysis also reaffirms some of the inherent limitations of the user tags compared to the controlled vocabularies; namely, subjectivity and impreciseness of the language. The general concern is that the overly subjective and imprecise tags can hinder searching. We come back to this in Sect. \ref{conclusion:folsonomy-flaw}.

To check whether there is a terminological gap between the game tags and professional annotations we matched all game tags to the domain thesaurus GTAA. GTAA is the sole vocabulary that is employed by the catalogers when annotating the same videos that are tagged in the game. We observed that only a small fraction of the unique game tags can be found in GTAA, around $8\%$. This demonstrates that there is indeed a terminological gap in the way the gamers and catalogers describe the videos.

To get a better understanding of what aspects of the video content are described by the game tags we carried out a manual classification of a sample of game tags. We used a classification schema that combines the Pahofsky-Shatford model and a classification framework built by Hollink at al. The results of the tag classification demonstrate that game tags predominantly describe objects using generic language and rarely refer to topics of a scene or the entire video. This is in sharp contrast with the professional annotations which exclusively target the topic(s) of the entire video and (less frequently) of particular scenes. The general conclusion is that game tags and the professional annotations are complementary both in terms of the terminology and in terms of what aspects of the video content they describe. This makes the game tags a valuable asset for at least the following two reasons. First, they provide a more online community-centric view of the content which will undoubtedly improve the access for the wider internet audience. Second, game tags are fine-grained annotations that target scenes, events, and objects within scenes. At this level of granularity they can facilitate tasks like \textit{event detection}, \textit{instance search} etc. Moreover, this level of granularity generally is unattainable for the professional annotations due to the enormous effort and time required. Game tags can step in and fill the void.
\subsection{Can we improve video retrieval with the help of user-generated data?}\label{conclusion:search}
Video fragment retrieval is widely recognized as an application scenario of particular business importance in the AV archival world. We evaluated the effectiveness of the game tags for two retrieval tasks: (i) \textit{visual search}, retrieval of fragments that feature visual appearances of the concept of interest and (ii) \textit{topical search}, retrieval of fragments that are about a given topic.
\subsubsection{Game tags for visual search}
When evaluating the effectiveness of game tags for visual search in Chapter \ref{chap:ecir}, we were mainly interested in two research questions. First, can game tags on their own or in combination with other existing types of metadata improve search? And second, does using only verified (consensus) tags give better search performance than using all game tags? In addressing these questions we used the quantitative system evaluation methodology. To this end, we created an evaluation dataset which consists of (i) a set of video fragments which were tagged in \textit{Waisda?}, (ii) a set of queries derived from real-life query logs, and (iii) relevance judgements. The relevance judgements were collected in a online user experiment wherein participants given a video fragment judged its relevance w.r.t the queries. The participants were instructed to judge a fragment to be relevant for a query if the concept denoted by the query visually appears in the fragment. We then created a number of search systems, ran them against the evaluation dataset and computed retrieval performance measures to assess their search effectiveness. The systems were carefully designed so that the collected evidence is sufficient to answer the research questions.

The results demonstrated that search based solely on game tags significantly outperforms search based on other types of metadata alone. In particular, game tags outperformed the in-house catalog tags and closed captions by $69\%$ and $39\%$, respectively. Moreover, combining the game tags with the other metadata types proved to be beneficial for search. In fact, the search engine that exploited all available metadata performed best, to large part due to the contribution of the game tags --- the observed performance improvement was $33\%$.

Considering only verified tags resulted in worse search performance than considering all game tags. In fact, all game tags outperformed the verified tags by $53\%$. This was mainly caused by the fact that search based on all game tags yields more relevant results and resulted in significantly higher recall. It seems the tag verification criterion is too conservative in a sense that it filters out tags that are in fact useful for search.

In Chapter \ref{chap:ecir} we established that game tags usually describe events and objects within scenes so it is not surprising that they excel at visual search. We also established that there is a difference in the focus and the scope of the game tags compared to the professional annotations; game tags being more fine-grained and professional annotations being more coarse-grained referring to the entire video and describing the prevalent topics. The in-house catalogue tags fit the latter profile: they are scarce and cover the topics of the video. This being said, quite predictably they fall short compared to the game tags when it comes to visual search. The closed-captions, on the other hand, are similar to the game tags in terms of focus and scope. Yet, game tags outperform them. This can be explained by the fact that closed-captions only cover the audio portion of the video and there are some aspects that have only visual representation. However, in order for the game tags to be able to compete with closed-captions there should be a \textit{sufficient} number of them assigned to the videos. What is a sufficient number of tags for a video is very hard to tell but in principle the more tags the better. And with time as more tags are added their search performance is improving and tables are turning in their favour. This was demonstrated in Sect. \ref{ecir:over-time-results}.

The overall conclusion is that game tags are well-suited for retrieving fragments that visually depict given object of interest. This property of the game tags makes them particularly appealing for business use-cases such as discovering/selling stock footage. 

\subsubsection{Game tags for topical search}
In Chapter \ref{chap:topicir-filter} we studied the added value of game tags for topical search. To this end, we used once again the quantitative system evaluation methodology which entails creation of evaluation dataset. When creating the dataset, we reused the same set of queries from the visual search study from Chapter \ref{chap:ecir}. The process of deriving the relevance judgements was automatised by exploiting the in-house catalog tags as the gold standard w.r.t. what topics are covered in the fragments. This allowed us to consider much larger set of fragments for the study since we were no longer dependent on human judges. 

The collected retrieval performance metrics showed that when it comes to topical search the game tags leave much to be desired. While the retrieval recall of the game tags is relatively satisfactory the precision is rather poor. So poor that it outweighs the good recall. The results were even worse for the verified tags. This was rather surprising since the initial expectations were that the consensus among the players reached on verified tags would result in tags that trustworthily describe the prominent aspects of the videos. Our hypothesis was that the tags referring to objects that are visually depicted in the videos are the leading reason for the poor retrieval performance. To test this hypothesis we performed a manual classification of samples of true positives and false positives retrieved using the game tags. The samples were classified w.r.t. to the content component they refer to --- \textit{audio}, \textit{visual}, or \textit{both} --- and using the tag classification schema developed in Chapter \ref{chap:kcap}. The results from the classification confirmed the hypothesis. The majority of the false positives, about $67\%$, were caused by tags referring to concepts that are only visually depicted. Moreover, most of these cases refer to general tags describing objects  appearing in the foreground and the background of the scenery. What is more important, our analysis showed that a significant portion of the topics are indeed captured by the game tags. However, there are
also many user tags that do not pertain to the subject (\textit{semantics}) of the video, but refer to the more \textit{syntactic} aspects such as what is \textit{seen} or \textit{heard}. It is the latter group that is responsible for the false positives and thereby hurting the search precision. Therefore, if user tags are to be used for topical search, a preprocessing step is required that will identify and filter out the non-topical user tags.

\subsubsection{Game tags for retrieval: Folksonomic flaw}\label{conclusion:folsonomy-flaw}
One of the main drawbacks of the user-generated tags compared to the controlled vocabularies is that tags are inherently imprecise, the so-called \textit{folksonomic flaw} \cite{Mathes04folksonomies,citeulike:468899}. The players of \textit{Waisda?} are unconstrained when entering tags and this can lead to several limitations. There is no explicit meaning assigned to the tags which can result in \textit{ambiguity}. For example, the tag \textit{ant} may refer to the eusocial insect of the family Formicidae. However, it may also refer to the relatively well-known software \textit{Apache Ant}\footnote{\url{http://ant.apache.org/}} (usually abbreviated to \textit{ant}). It may even be an acronym for ``Actor Network Theory". Without explicit disambiguation there is no way to tell the intended meaning. Another limitation of game tags stems from the presence of \textit{synonyms} in natural languages. For example, both the tags \textit{mac} and \textit{macintosh} can be used to denote Apple Macintosh computer. If the searcher searches for \textit{mac} but only \textit{macintosh} is present in the system the search will be unsuccessful. Yet another limitation is imposed by the general level of \textit{tag literacy}. Plural and singular forms, conjugated words and compound words may be used, as well as specialised tags and ``nonsense" tags designed as unique markers that are shared between a group of friends or co-workers. These limitations are not exclusive to game tags. The other metadata types suffer from them as well, albeit to a lesser extent. Closed-captions and in-house catalog tags can be ambiguous and have issues with synonyms as well. The literacy is a less of a concern for them given their more controlled nature. 

In the search studies described in Chapter \ref{chap:ecir} and \ref{chap:topicir-filter} we did not use any special mechanisms to combat the tag limitations outlined above. We did use stemming which is a standard technique to deal with word inflexions by reducing the inflected words to their root(stem). Tag literacy was not an issue in our search studies as the queries were all standard words and the word inflexions were taken care of by stemming. In other words, the effect of low literacy tags, was not triggered by the queries in our query set. Ambiguity was also not an issue since the majority of the queries in our query set are not polysemic. And even when there is more than one meaning assigned to the queries usually the difference among them is nuanced so they can effectively be used interchangeably. Synonymy can be addressed by query expansion where the synonyms are added to the query and searched for as well. It will be interesting to extend the studies from Chapter \ref{chap:ecir} and \ref{chap:topicir-filter} to deal with synonyms in future work.

\subsection{Can the quality of user-generated tags for videos be evaluated and improved?}
In Chapter \ref{chap:topicir-filter} we demonstrated that game tags are are not well suited for retrieving video fragments based on topic. This is mainly caused by the overwhelming presence of game tags which are not valid topical descriptors. In the second half of Chapter \ref{chap:topicir-filter} we evaluated the quality of the game tags as topical descriptors with the intention to detect and filter out the ones that are not referring to topics. We explored several methods for predicting the tag quality --- TF-IDF-based filtering, player reputation-based filtering, and topic models to name a few. The success of each method was judged against the evaluation dataset developed in the topical search study.

While the different methods that we studied performed with various success, the conclusion is that the
game tags can be successfully exploited for topical video search provided there is a filtering process that would reduce or eliminate the effect of the non-topical tags. Our results show that after TF-IDF-based filtering game tags can emulate the retrieval performance of the best performing system that utilizes manually crafted metadata for search. Moreover, combining TF-IDF filtered game tags with the manually crafted metadata yields an improvement of retrieval performance by $18\%$. The improvement is attributed to the increased retrieval recall stemming from the game tags. An important consequence of this result is that tagging games provide a cost-effective alternative for AV collection owners that do not possess the required manpower to manually annotate their material.

\section{Discussion and Further Research}
In this thesis we investigated the added value of the tags collected with the video-labelling game \textit{Waisda?} for video fragment retrieval. The general conclusion is that the game tags improve retrieval and on average perform better compared to the manually-crafted metadata and closed captions. This statement comes with three caveats. First, in our setting the \textit{taggers} and the \textit{searchers} originate from the same community which entails significant terminological overlap between the \textit{keywords} used for search and the tags ascribed to the videos. We believe this to be the main contributing factor for the success of the game tags for search in the context of our study. And while it may look like a limitation at first, in practice it is not. The terminology employed when tagging is general enough to cater to the needs of all but the expert searchers which may use more specialized (specific) terms when searching. Second, in this work we considered only \textit{keyword-based search} thus the said improvement in retrieval is limited to this modality. At the time of writing, other search modalities such as \textit{content-based video retrieval} \cite{veltkamp2013state} are gaining more attention, however keyword-based search is still the most prominent one, especially on the Web, and is likely to remain so in future. Third, in this work we focussed on single domain (genre), non-fictional TV Comedy. Naturally, the obtained results are bound to this domain. However, the qualitative analysis of the tags revealed that they are usually general concepts describing visual objects and as such are not so tightly coupled with the genre of the video content they are describing. Our expectation is that the game tags will perform well for most of the non-fictional TV genres which appeal to a wider audience. It remains to be seen whether this will be the case for the fictional genres where more symbolism and abstract expressions can be expected. We hypothesise that without properly instructing the taggers or targeting a niche sub-community of experts the outcome will be less satisfactory.

\subsection{The Bigger Picture}
In the recent years there were advancements in many fields that are related to the scope of the work presented in this thesis. Following is a non-exhaustive list of the most relevant ones.

\paragraph{Computer Vision.} Thanks to the advancements made in the area of deep learning \cite{Bengio:2013:RLR:2498740.2498889,Arel:2010:RFD:1921914.1921920,Schmidhuber:deep-learning} the field of computer vision witnessed important breakthroughs in the recent years. Using vast number of high-resolution example images, the deep convolutional neural networks can be trained to classify and label scenes and objects depicted in new unseen images \cite{NIPS2012_4824,10.1109/TPAMI.2012.231}. An excellent example of this idea put into practice is the Microsoft's Project Adam \cite{project-adam}. The Adam computer vision system is hailed to be advanced enough to tell the difference, for example, between a picture of a Pembroke and a Cardigan Corgi (dog breeds), a task that is quite difficult even for a person. The Adam system is fuelled by a deep convolutional neural network which has been trained with over 14 million images split up into 22,000 categories drawn from the ImageNet database\footnote{\url{http://www.image-net.org/}}. Another computer vision task that has benefited greatly from deep learning is face recognition. The Facebook's DeepFace system is able to tell whether two unfamiliar photos of faces show the same person with accuracy almost as high as that of a human regardless of variations in lighting or whether the person in the picture is directly facing the camera \cite{Taigman_2014_CVPR,DBLP:conf/cvpr/ZhangPTFB15}. The deep learning techniques have been applied to the medium of video as well. Karpathy et al. used convolutional neural networks for large-scale video classification. Deep learning has also been exploited to for human action recognition in videos \cite{DBLP:journals/corr/SimonyanZ14,Ji:2013:CNN:2412386.2412939}. In spite of all these advancements, the holy grail of computer vision, \textit{total scene understanding}, is still well outside the reach or the current state-of-the-art systems. This is even more true for the medium of video which compared to still images has the additional temporal dimension. A direct consequence of the temporal dimension and an excellent example of the complexity of scene understanding is the so-called \textit{Kuleshov effect}. It is a mental phenomenon by which viewers derive more meaning from the interaction of two sequential shots than from a single shot in isolation \cite{mobbs2006kuleshov}. This means that the meaning of a scene is not determined only by the scene itself but also by the scenes that preceded it. While the total scene understanding is presently unattainable for computers it is relatively easy for the average \textit{Waisda?} player. We have demonstrated that the \textit{Waisda?} tags refer ---among other things--- to the more abstract aspects of the videos such as topics.
This hints to a potential hybrid approach to video annotation that combines computer vision and a human-computation technique such as \textit{Waisda?}. The computer vision system will detect and label objects, actions, generic scene classes, etc. and the \textit{Waisda?} players will tag the more abstract aspect relating to the meaning of the scenes. In such a system there will be overlap, the computer vision system and the \textit{Waisda?} players may ascribe the same tag. This redundancy is an affirmation of the correctness of the tag. A potential drawback of the computer vision systems in general is that they need to be trained to learn new concepts. Granted the Adam system can recognize over 22,000 concepts but this is still a finite and potentially limited set. The hybrid approach could be used to overcome this problem. The computer vision system can learn new concepts from the \textit{Waisda?} tags. Indeed, the \textit{Waisda?} tags and the associated scenes can be used as training examples for the computer vision system to learn the ``unseen" concepts denoted by the tags.

\paragraph{Cultural Heritage.} In the recent years the bulk of the European cultural heritage has been undergoing a process of digitisation. A testament of that was the European Union funded project PrestoPRIME\footnote{\url{http://www.prestoprime.org/}} about digitisation and preservation of the European audio-visual heritage. The project's consortium included all major European national Audio-Visual archives and among many of the project's deliverables was \textit{Waisda?}. The project also delivered a digitisation and preservation framework that enables the conversion of thousands of hours of audio-visual material from analog to digital form. However, simply by being in digital form and without descriptive metadata makes the audio-visual collections only marginally more accessible than being on analog tapes. Manual annotation by professional catalogers is prohibitively expensive. According to empirical evidence it takes five times the duration of a video for a cataloger to annotate it. In this thesis we have demonstrated that GWAPs such as \textit{Waisda?} provide a cost-effective alternative. It is relatively inexpensive to deploy \textit{Waisda?} and games alike and after the suitable processing the collected tags can be exploited for video retrieval. This is a game-changer for the audio-visual archives. They can deploy Waisda? and collect tags for the hundreds of thousands hours of video material which are not annotated simply because it requires too much time and effort for the catalogers to do it manually. The Sound and Vision institute, the Dutch national archive, included the tags collected with \textit{Waisda?} in the in-house workflows and is cooperating with other institutions in deploying \textit{Waisda?} in various domains. In this thesis we developed an extension module for \textit{Waisda?} which enables seamless integration of the game in any audio-visual collection workflow.


We believe that this is an important step toward making the AV material more accessible on the Web and in general making the Web more connected.




%TODO You might get this even to a higher level by saying some things about how your research relates to the more general goals of AV-archives in our society.

\subsection{Future Directions}
Video labelling games are \textit{human-based computation} technique. Needless to say, anyone wishing to successfully deploy a \textit{Waisda?} instance or other games alike ought not neglect the \textit{human factor}. Even the most perfectly executed video-labelling campaign from technological standpoint will fail if there are no taggers to contribute. In other words, marketing is vital. The empirical evidence collected from both \textit{Waisda?} pilots supports this claim. On both occasions the bulk of the tags was accumulated during periods when there was active marketing campaign for promoting the game. We believe that carefully applying the marketing mechanisms for acquiring new players by targeting the right online communities is a key factor for success. Our hypothesis is that engaging the right community leads to better tags. Understanding the relationship between target marketing and user engagement on one side and the quality of the resulting tags on the other is a worthwhile direction for future research.

What makes video annotation a difficult task is the fact that video is a medium that is extremely rich in meaning. The taggers can get overwhelmed by the complex interplay of objects and events especially in the fast-paced game setting. We believe that the game design directly influences the focus and quality of the resulting tags. For example, significant portion of the \textit{Waisda?} tags refer to more noticeable aspects of the content such as moving objects in the background or in the foreground, or prominent stationary objects. This is hardly surprising, after all these are things that are easy to reach consensus on and ultimately that is the goal of the game from the perspective of the players. We hypothesise that if the underlying goals\footnote{An example goal could be tagging the occurrences of specific type of events.} of the game creators are better aligned with the game objectives from the perspective of the players that will result in increased quality of the resulting tags. Understanding how the game design and game objectives influence the quality of the resulting tags is another worthwhile direction for future research. 

We foresee that video-labelling games will be increasingly used for video annotation and eventually will become the dominant method due to their cost-effectiveness. Future research could focus on making them more effective by engaging the right communities and stimulating them to produce better tags by setting appropriate game objectives.  

%State the main conclusion - game tags have added value for retrieval.

%Discuss the limitations of the conclusions 

%Discuss the implications of the conclusion

%Future research - focus more on the human factor: marketing and niche-sourcing and user-guidance.


 